name: Importa ricette da URLs (FULL)

on:
  workflow_dispatch: {}
  push:
    branches: [ main ]
    paths:
      - ".github/workflows/import-urls-full.yml"

permissions:
  contents: write

concurrency:
  group: auto-import
  cancel-in-progress: true

jobs:
  ping:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Sanity check
        shell: bash
        run: |
          set -e
          node -v
          pwd
          ls -lah
          echo "cartella script:"
          ls -lah script || true
          echo "assets/json:"
          ls -lah assets/json || true

      - name: Ensure urls.txt
        shell: bash
        run: |
          set -e
          if [ ! -s urls.txt ]; then
            : > urls.txt
            echo "https://ricette.giallozafferano.it/Gnocchi-alla-sorrentina.html" >> urls.txt
            echo "https://ricette.giallozafferano.it/Pollo-alla-cacciatora.html" >> urls.txt
            echo "https://ricette.giallozafferano.it/Lasagne-alla-Bolognese.html" >> urls.txt
            echo "https://ricette.giallozafferano.it/Tiramisu.html" >> urls.txt
            echo "https://ricette.giallozafferano.it/Pesto-alla-genovese.html" >> urls.txt
            echo "https://ricette.giallozafferano.it/Minestrone-di-verdure.html" >> urls.txt
          fi
          echo "Prime 5 URL:"
          head -n 5 urls.txt || true
          echo "Totale URL:"
          wc -l urls.txt
      - name: Discover URLs (GZ)
        run: |
          node script/discover-gz.mjs
          echo "---- anteprima nuove ----"
          head -n 20 new_urls.txt || true
      - name: Append discovered -> urls.txt (dedup)
        run: |
          # Se ci sono URL nuovi, appendo e deduplico
          if [ -s new_urls.txt ]; then
            cat new_urls.txt >> urls.txt
            # dedup preservando l'ordine
            awk '!seen[$0]++' urls.txt > urls.dedup && mv urls.dedup urls.txt
          fi
          echo "Prime 10 URL in urls.txt:"
          head -n 10 urls.txt || true
          echo "Totale URL in urls.txt:"
          wc -l urls.txt
      - name: Use discovered list (overwrite urls.txt)
        run: |
          if [ -s new_urls.txt ]; then
            echo "Sovrascrivo urls.txt con le nuove URL..."
            cp new_urls.txt urls.txt
            echo "Prime 5 righe:"
            head -n 5 urls.txt
            echo "Totale:"
            wc -l urls.txt
          else
            echo "Nessuna new_urls.txt trovata o vuota: salto import."
            # Per sicurezza svuoto urls.txt per evitare import di vecchi residui
            : > urls.txt
          fi
      - name: Probe a few GZ pages (headers+snippet)
        run: |
          set -e
          # Prendo le prime 3 URL da urls.txt
          head -n 3 urls.txt > probe_list.txt

          echo "== HEADERS =="
          while read -r u; do
            echo "--- $u"
            curl -I -L --max-redirs 5 \
              -H "User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36" \
              -H "Accept-Language: it-IT,it;q=0.9" \
              "$u" || true
          done < probe_list.txt

          echo
          echo "== SNIPPET =="
          while read -r u; do
            echo "--- $u"
            curl -sL --max-redirs 5 \
              -H "User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36" \
              -H "Accept-Language: it-IT,it;q=0.9" \
              "$u" | head -c 800 || true
            echo
          done < probe_list.txt
      - name: Probe a few GZ pages (headers+snippet)
        run: |
          set -e
          # Prendo le prime 3 URL da urls.txt
          head -n 3 urls.txt > probe_list.txt

          echo "== HEADERS =="
          while read -r u; do
            echo "--- $u"
            curl -I -L --max-redirs 5 \
              -H "User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36" \
              -H "Accept-Language: it-IT,it;q=0.9" \
              "$u" || true
          done < probe_list.txt

          echo
          echo "== SNIPPET =="
          while read -r u; do
            echo "--- $u"
            curl -sL --max-redirs 5 \
              -H "User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36" \
              -H "Accept-Language: it-IT,it;q=0.9" \
              "$u" | head -c 800 || true
            echo
          done < probe_list.txt

      - name: Import batch
        shell: bash
        run: |
          set -e
          if [ -f script/import-recipes.mjs ]; then
            echo "Eseguo importâ€¦"
            node script/import-recipes.mjs urls.txt 30 > new_recipes.json
            if [ ! -s new_recipes.json ]; then
              echo "[]"> new_recipes.json
            fi
          else
            echo "AVVISO: script/import-recipes.mjs assente. Skip import."
            echo "[]"> new_recipes.json
          fi
          echo "Anteprima new_recipes.json:"
          head -c 800 new_recipes.json || true
          echo

      - name: Merge dataset
        shell: bash
        run: |
          set -e
          DATA="assets/json/recipes-it.json"
          mkdir -p assets/json
          if [ ! -f "$DATA" ]; then echo "[]"> "$DATA"; fi
          if [ ! -s new_recipes.json ]; then
            echo "Nessuna nuova ricetta, salto merge"
            exit 0
          fi
          if [ -f script/merge-recipes.mjs ]; then
            node script/merge-recipes.mjs "$DATA" new_recipes.json > "${DATA}.tmp"
            mv "${DATA}.tmp" "$DATA"
          else
            echo "merge-recipes.mjs assente, uso merge fallback"
            node -e '
              const fs=require("fs");
              const a=JSON.parse(fs.readFileSync("assets/json/recipes-it.json","utf8"));
              const b=JSON.parse(fs.readFileSync("new_recipes.json","utf8"));
              const key = r => (r && (r.id || r.url || r.title)) || Math.random().toString(36).slice(2);
              const map=new Map();
              for(const r of a) map.set(key(r), r);
              for(const r of b) map.set(key(r), r);
              fs.writeFileSync("assets/json/recipes-it.json", JSON.stringify([...map.values()], null, 2));
            '
          fi
          echo "Dimensione dataset:"
          wc -c assets/json/recipes-it.json

      - name: Commit and push
        shell: bash
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          if git diff --cached --quiet; then
            echo "Niente da commitare"
            exit 0
          fi
          COUNT=$(node -e "try{console.log((JSON.parse(require('fs').readFileSync('new_recipes.json','utf8'))||[]).length||0)}catch(e){console.log(0)}")
          git commit -m "Import ricette automatico (+$COUNT)"
          git push

      - name: Echo
        run: echo "OK"
